{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Task 1: Linear Regression**\n",
    "        `Optimzed Regression `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step1: Importing Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step2: Loading and Inspecting the Dataset**\n",
    "```\n",
    "Read the dataset from a CSV file.\n",
    "Display the first few rows and dataset structure.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated path\n",
    "dataset_path = \"https://raw.githubusercontent.com/ikalisa1/linear_regression_model/refs/heads/main/insurance.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "display(df.head())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step3: Data Preprocessing**\n",
    "```\n",
    "Turning categorical variables into numbers using one-hot encoding..\n",
    "Separate features (X) and target variable (y).\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, drop_first=True)\n",
    "X = df.drop(columns=['charges'])  # Features\n",
    "y = df['charges']  # Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step4:  Train-Test Split**\n",
    "\n",
    "`Split the data into training (80%) and testing (20%) sets.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step5: Feature Scaling**\n",
    "\n",
    "`Normalize the feature values for better model performance.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step6: Data Visualization**\n",
    "\n",
    "```\n",
    "Histogram of Target Variable (Medical Charges)\n",
    "Correlation Heatmap to Check Relationships Between Variables\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(y, bins=30, kde=True)\n",
    "plt.title(\"Distribution of Medical Charges\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7: Correlation Heatmap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df.corr().fillna(0), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and Optimize Three Models**\n",
    "\n",
    "```\n",
    "(a) Linear Regression (Using Gradient Descent)\n",
    "Perform hyperparameter tuning using GridSearchCV on SGDRegressor.\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lr = {'alpha': [0.0001, 0.001, 0.01, 0.1], 'max_iter': [500, 1000, 5000]}\n",
    "lr_grid_search = GridSearchCV(SGDRegressor(), param_grid_lr, cv=5, scoring='neg_mean_squared_error', verbose=1)\n",
    "lr_grid_search.fit(X_train, y_train)\n",
    "best_lr = lr_grid_search.best_estimator_\n",
    "print(f\"Best Linear Regression params: {lr_grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Plot Loss Curve for Linear Regression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "\n",
    "for max_iter in [100, 500, 1000, 5000]:\n",
    "    model = SGDRegressor(max_iter=max_iter, alpha=lr_grid_search.best_params_['alpha'])\n",
    "    model.fit(X_train, y_train)\n",
    "    train_loss.append(mean_squared_error(y_train, model.predict(X_train)))\n",
    "    test_loss.append(mean_squared_error(y_test, model.predict(X_test)))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot([100, 500, 1000, 5000], train_loss, marker='o', label='Train Loss')\n",
    "plt.plot([100, 500, 1000, 5000], test_loss, marker='s', label='Test Loss')\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Mean Squared Error\")\n",
    "plt.title(\"Loss Curve for Linear Regression\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Decision Tree Regression**\n",
    "`Perform hyperparameter tuning on DecisionTreeRegressor.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_dt = {'max_depth': [3, 5, 10, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}\n",
    "dt_grid_search = GridSearchCV(DecisionTreeRegressor(), param_grid_dt, cv=5, scoring='neg_mean_squared_error', verbose=1)\n",
    "dt_grid_search.fit(X_train, y_train)\n",
    "best_dt = dt_grid_search.best_estimator_\n",
    "print(f\"Best Decision Tree params: {dt_grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Random Forest Regression**\n",
    "`Perform hyperparameter tuning on RandomForestRegressor.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rf = {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 10, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}\n",
    "rf_grid_search = GridSearchCV(RandomForestRegressor(), param_grid_rf, cv=5, scoring='neg_mean_squared_error', verbose=1)\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "best_rf = rf_grid_search.best_estimator_\n",
    "print(f\"Best Random Forest parameters: {rf_grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step8: Model Evaluation**\n",
    "```\n",
    "(Finding the Best Model)\n",
    "Compute Mean Squared Error (MSE) for all three models.\n",
    "Select the model with the lowest MSE.\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_lr = mean_squared_error(y_test, best_lr.predict(X_test))\n",
    "mse_dt = mean_squared_error(y_test, best_dt.predict(X_test))\n",
    "mse_rf = mean_squared_error(y_test, best_rf.predict(X_test))\n",
    "\n",
    "best_model = min([(mse_lr, best_lr, \"Linear Regression\"), (mse_dt, best_dt, \"Decision Tree\"), (mse_rf, best_rf, \"Random Forest\")], key=lambda x: x[0])\n",
    "print(f\"Best model: {best_model[2]} with MSE: {best_model[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step9: Save the Best Model**\n",
    "`Store the model using joblib so it can be used for predictions later.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(best_model[1], \"best_health_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 10: Visualizing Model Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"Linear Regression\", \"Decision Tree\", \"Random Forest\"]\n",
    "mse_values = [mse_lr, mse_dt, mse_rf]\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=models, y=mse_values, palette=\"viridis\")\n",
    "plt.title(\"Model Performance Comparison (MSE)\")\n",
    "plt.ylabel(\"Mean Squared Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 11: Load and Predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = joblib.load(\"best_health_model.pkl\")\n",
    "sample_input = np.array(X_test[0]).reshape(1, -1)\n",
    "prediction = loaded_model.predict(sample_input)\n",
    "print(f\"Predicted medical charge: {prediction[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **In summary,  of the process!**\n",
    "\n",
    "First, we bring in all the necessary tools (libraries) to work with. Then, we load the data from a CSV file and take a quick look at it to understand what weâ€™re working with. Next, we get the data ready by turning any categories into numbers and splitting it into training and testing sets. To make sure our models work well, we scale the features, so everything is on the same level.\n",
    "\n",
    "We then take a closer look at the data with visualizations like histograms and heatmaps. After that, we train a few models like Linear Regression, Decision Trees, and Random Forests, tuning them for the best performance. Once we compare how they perform with Mean Squared Error (MSE), we pick the best one.\n",
    "\n",
    "The top model gets saved using joblib, so we can use it later. Finally, we load the model and predict medical charges, comparing how well each model did.\n",
    "\n",
    "This whole process helps us build, test, and use a powerful predictive model!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
